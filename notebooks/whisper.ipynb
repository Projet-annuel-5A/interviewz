{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import warnings\n",
    "import configparser\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from datetime import datetime\n",
    "from pyannote.audio import Pipeline as AudioPipeline\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                          AutoModelForSpeechSeq2Seq,\n",
    "                          AutoProcessor,\n",
    "                          AutoModelForAudioClassification,\n",
    "                          Wav2Vec2FeatureExtractor,\n",
    "                          pipeline as huggingface_pipeline)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "filename = ''"
   ],
   "id": "3c45168ca698caba",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stt_model_id = 'openai/whisper-large-v3'\n",
    "stt_torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "stt_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    stt_model_id, torch_dtype=stt_torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "stt_model.to(device)\n",
    "stt_processor = AutoProcessor.from_pretrained(stt_model_id)\n",
    "stt_pipeline = huggingface_pipeline(\n",
    "    'automatic-speech-recognition',\n",
    "    model=stt_model,\n",
    "    tokenizer=stt_processor.tokenizer,\n",
    "    feature_extractor=stt_processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=1,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=stt_torch_dtype,\n",
    "    device=device,\n",
    ")"
   ],
   "id": "61b0efe637b4cf4c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = stt_pipeline(filename, generate_kwargs={'language': 'french', 'task': 'transcribe'})\n",
    "result['text']"
   ],
   "id": "c3b57695873421a8",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "without pipeline",
   "id": "b5d4faa5d134390f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:36:40.709290Z",
     "start_time": "2024-05-12T20:36:40.697727Z"
    }
   },
   "cell_type": "code",
   "source": "audio_sample = '../files/output/20240512/test/audio/speaker_000/part_00000.wav'",
   "id": "29b4dd9fe98ddc45",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:36:50.122101Z",
     "start_time": "2024-05-12T20:36:43.064361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, Wav2Vec2FeatureExtractor, AutoModelForSpeechSeq2Seq\n",
    "import torchaudio\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large-v3\")\n",
    "feature_extractor = processor.feature_extractor"
   ],
   "id": "5c98a590583c9ec8",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:36:50.153100Z",
     "start_time": "2024-05-12T20:36:50.123103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_sampling_rate = feature_extractor.sampling_rate\n",
    "waveform, audio_sampling_rate = torchaudio.load(audio_sample)\n",
    "resampler = torchaudio.transforms.Resample(audio_sampling_rate, model_sampling_rate)\n",
    "resampled_waveform = resampler(waveform).squeeze().numpy()"
   ],
   "id": "5f2905d96b693dd",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:36:51.620660Z",
     "start_time": "2024-05-12T20:36:51.600663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_features = processor(\n",
    "    resampled_waveform, sampling_rate=model_sampling_rate, return_tensors=\"pt\"\n",
    ").input_features"
   ],
   "id": "d645cdda233c81d6",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:37:56.098918Z",
     "start_time": "2024-05-12T20:37:32.652395Z"
    }
   },
   "cell_type": "code",
   "source": "predicted_ids = model.generate(input_features, language=\"french\", task=\"transcribe\")",
   "id": "a0e6b7b8ae021553",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:38:27.536540Z",
     "start_time": "2024-05-12T20:38:27.468537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "transcription[0]"
   ],
   "id": "2b895cd81fcda988",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:50:12.448548Z",
     "start_time": "2024-05-12T20:50:12.429547Z"
    }
   },
   "cell_type": "code",
   "source": "transcription[0].strip() == transcription[1].strip()",
   "id": "14241be6e5922214",
   "execution_count": 15,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
