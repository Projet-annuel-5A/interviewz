{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:35:30.644348Z",
     "start_time": "2024-05-24T04:35:30.641258Z"
    }
   },
   "cell_type": "code",
   "source": "# pip install tf-keras",
   "id": "841ded60c2ec7562",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:44:49.929663Z",
     "start_time": "2024-05-24T04:44:44.800719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "from deepface import DeepFace\n",
    "import torch.nn as nn\n",
    "from transformers import pipeline, AutoImageProcessor, AutoModelForImageClassification"
   ],
   "id": "cc8addf3d5914558",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:46:40.842549Z",
     "start_time": "2024-05-24T04:46:40.227383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = 'c:/Users/dalex/Downloads/sad.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "original_path= ''\n",
    "modified_path = ''\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:\n",
    "    temp_file_path = temp_file.name\n",
    "    cv2.imwrite(temp_file_path, image)\n",
    "    original_path = temp_file_path\n",
    "\n",
    "image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:\n",
    "    temp_file_path = temp_file.name\n",
    "    cv2.imwrite(temp_file_path, image_bgr)\n",
    "    modified_path = temp_file_path\n",
    "    \n",
    "print('Original image saved to', original_path)\n",
    "print('Modified image saved to', modified_path)"
   ],
   "id": "ffc9ad60e4215807",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T05:38:01.005726Z",
     "start_time": "2024-05-24T05:38:00.339550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "no_face_path = 'c:/Users/dalex/AppData/local/temp/tmpx92yanqz.jpg'\n",
    "try:\n",
    "    objs = DeepFace.analyze(img_path=original_path, actions=['emotion'])\n",
    "    results = objs[0]['emotion']\n",
    "    emotions = {k: v for k, v in sorted(results.items(), key=lambda x: x[1], reverse=True)}\n",
    "except ValueError as e:\n",
    "    emotions = {'angry': 0.0,\n",
    "                'neutral': 0.0,\n",
    "                'sad': 0.0,\n",
    "                'happy': 0.0,\n",
    "                'fear': 0.0,\n",
    "                'surprise': 0.0,\n",
    "                'disgust': 0.0\n",
    "                }\n",
    "    \n",
    "emotions"
   ],
   "id": "e3a04b6029772290",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\n",
    "if detections is not None and len(detections) > 0:\n",
    "    print(\"Face detected!\")\n",
    "else:\n",
    "    print(\"No face detected.\")"
   ],
   "id": "36f754b4c6223e89",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T05:16:51.262369Z",
     "start_time": "2024-05-24T05:16:50.966030Z"
    }
   },
   "cell_type": "code",
   "source": "original_objs = DeepFace.analyze(img_path = original_path, actions = ['detect_face', 'emotion'])",
   "id": "81b83be58eb3b556",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:51:43.739207Z",
     "start_time": "2024-05-24T04:51:43.735600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emotions = original_objs[0]['emotion']\n",
    "emotions"
   ],
   "id": "8fb2f0aa2ed9268f",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:51:46.053512Z",
     "start_time": "2024-05-24T04:51:46.050277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sorted_values = {k: v for k, v in sorted(emotions.items(), key=lambda x: x[1], reverse=True)}\n",
    "print('Sorted values:', sorted_values)"
   ],
   "id": "538cbdebba4b7ad",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hugginface model With pipeline",
   "id": "9f2d331ae058f527"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:27:45.950747Z",
     "start_time": "2024-05-24T04:27:44.880488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = \"image-classification\"\n",
    "model_id = \"dima806/facial_emotions_image_detection\"\n",
    "pipe = pipeline(task, model_id, top_k=7)\n",
    "\n",
    "def predict(image_path: str) -> dict[str, float]:\n",
    "    result = pipe(image_path)\n",
    "\n",
    "    output = {}\n",
    "    for entry in result:\n",
    "        output[entry['label']] = entry['score'] * 100\n",
    "\n",
    "    sorted_values = {k: v for k, v in sorted(output.items(), key=lambda x: x[1], reverse=True)}\n",
    "\n",
    "    return sorted_values\n",
    "\n",
    "result_1 = predict(image_path)\n",
    "result_1"
   ],
   "id": "fbcd13fefcf588fa",
   "execution_count": 53,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Without pipeline",
   "id": "e11df00289ab12ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:27:56.890211Z",
     "start_time": "2024-05-24T04:27:56.291924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"dima806/facial_emotions_image_detection\", output_attentions=True)\n",
    "model = AutoModelForImageClassification.from_pretrained(\"dima806/facial_emotions_image_detection\", output_attentions=True)\n",
    "assert model.config.output_attentions == True"
   ],
   "id": "8904d588d5ca33c0",
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:41:47.265279Z",
     "start_time": "2024-05-24T04:41:38.903093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image = cv2.imread(image_path)\n",
    "cv2.imshow('Frame', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow('Frame', image_bgr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# pil_image_1 = Image.fromarray(image_rgb)\n",
    "# pil_image_2 = Image.fromarray(image)"
   ],
   "id": "52c9ad8025cace07",
   "execution_count": 75,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:25:35.596036Z",
     "start_time": "2024-05-24T04:25:35.414407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "attention_weights = outputs.attentions\n",
    "print(logits)\n",
    "print(attention_weights)"
   ],
   "id": "301ee0b08069b1fb",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T04:09:17.219090Z",
     "start_time": "2024-05-24T04:09:17.215463Z"
    }
   },
   "cell_type": "code",
   "source": "logits",
   "id": "87eced7d14bb8ee2",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "\n",
    "m = nn.Softmax(dim=0)\n",
    "values = m(logits[0])\n",
    "\n",
    "w_values = np.zeros(7)\n",
    "for i in range(7):\n",
    "    result = values[i].item() * attention_weights[i]\n",
    "    w_values[i] = torch.sum(result)\n",
    "\n",
    "# Convert to percentage\n",
    "total = np.sum(w_values)\n",
    "w_values = w_values*100/total\n",
    "\n",
    "values_dict = dict(zip(model.config.id2label.values(), w_values))\n",
    "result_2 = {k: v for k, v in sorted(values_dict.items(), key=lambda x: x[1], reverse=True)}"
   ],
   "id": "2489a08652232041",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:17:02.528474Z",
     "start_time": "2024-05-14T02:17:02.517588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(result_1)\n",
    "print(result_2)"
   ],
   "id": "d53aef960830a43f",
   "execution_count": 68,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
